{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdP73PAAm6bu"
   },
   "source": [
    "# Neural Networks with TensorFlow and Keras\n",
    "\n",
    "Deep neural networks tend to be massive with dozens or even hundreds of layers, that's where the term \"deep\" comes from. You can build one of these deep networks using only weight matrices as we did in the previous notebook, but in general it's very cumbersome and difficult to implement. TensorFlow has a nice API called **Keras** that provides a nice way to efficiently build large neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHb_h16-YOes"
   },
   "source": [
    "## Import Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVpuOzdonZdj"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "NBOTTYzQVaLz",
    "outputId": "95fa3fdd-5870-4e39-99b2-2c3da82d5971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:\n",
      "\t• TensorFlow version: 2.6.2\n",
      "\t• tf.keras version: 2.6.0\n",
      "\t• GPU device not found. Running on CPU\n"
     ]
    }
   ],
   "source": [
    "print('Using:')\n",
    "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
    "print('\\t\\u2022 tf.keras version:', tf.keras.__version__)\n",
    "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tcHviD_uYQ5R"
   },
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8cMpbPrngfy"
   },
   "source": [
    "Now we're going to build a larger network that can solve a (formerly) difficult problem, identifying text in an image. Here we'll use the MNIST dataset which consists of greyscale handwritten digits. Each image is 28x28 pixels, you can see a sample below\n",
    "\n",
    "<img src='assets/mnist.png'>\n",
    "\n",
    "Our goal is to build a neural network that can take one of these images and predict the digit in the image.\n",
    "\n",
    "First up, we need to get the dataset we are going to use to train and test our Neural Network. We will get our dataset using the [`tensorflow_datasets`](https://www.tensorflow.org/datasets) package. TensorFlow Datasets is a repository of datasets ready to use with TensorFlow. TensorFlow Datasets has a wide variety of datasets to train your machine learning models for many different tasks, ranging from text to video. For a full list of the datasets available in TensorFlow Datasets check out the [TensorFlow Datasets Catalog](https://www.tensorflow.org/datasets/catalog/overview#all_datasets).\n",
    "\n",
    "\n",
    "The code below will load the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "C1g79MKHnhsT",
    "outputId": "25221d70-5079-40e1-cd5a-999ca81c7e6b"
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "'''\n",
    "1. We can define what feature we expect : in te first place we need to define the name of dataset, \n",
    " \n",
    "2. In the second place we need to define which part of data we need, for example here we mention ok\n",
    "we want 'train set',\n",
    "\n",
    "3. In the next place we mentioned that \"supervised = true\" means it returns the label of each data.\n",
    "\n",
    "4. and in the last part we define we need some information about the dataset features.\n",
    "\n",
    "5. OUTPUT:so we have two output: training_set and dataset_info\n",
    "\n",
    "'''\n",
    "\n",
    "training_set, dataset_info = tfds.load('mnist', split = 'train', as_supervised = True, with_info = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The MNIST database of handwritten digits.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mnist/3.0.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info.full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='mnist',\n",
       "    full_name='mnist/3.0.1',\n",
       "    description=\"\"\"\n",
       "    The MNIST database of handwritten digits.\n",
       "    \"\"\",\n",
       "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
       "    data_path='C:\\\\Users\\\\1234\\\\tensorflow_datasets\\\\mnist\\\\3.0.1',\n",
       "    download_size=11.06 MiB,\n",
       "    dataset_size=21.00 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{lecun2010mnist,\n",
       "      title={MNIST handwritten digit database},\n",
       "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
       "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
       "      volume={2},\n",
       "      year={2010}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "82QelXpcYdmD"
   },
   "source": [
    "## Inspect the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VjDZz2a90Iyb"
   },
   "source": [
    "We have loaded the training data into `training_set` and loaded dataset information into `dataset_info`.  Let's get the total number of classes and the total number of images in our training set from `dataset_info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "9euLZQJD0g05",
    "outputId": "ba83ff2e-0702-45cb-ba6f-39dad0cb3061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 classes in our dataset\n",
      "\n",
      "There are 60,000 images in the training set\n"
     ]
    }
   ],
   "source": [
    "num_classes = dataset_info.features['label'].num_classes\n",
    "print('There are {:,} classes in our dataset'.format(num_classes))\n",
    "\n",
    "num_training_examples = dataset_info.splits['train'].num_examples\n",
    "print('\\nThere are {:,} images in the training set'.format(num_training_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WpZNLP-QnyRG"
   },
   "source": [
    "We can use `training_set` as an iterator so, we can use the following statement to loop through the dataset:\n",
    "\n",
    "```python\n",
    "for image, label in training_set:\n",
    "    ## do things with images and labels\n",
    "```\n",
    "\n",
    "Let's print the shape and dtype of our images and labels. We'll use the `.take(1)` method to only choose one element from our dataset. Since our dataset consists of images, the `.take(1)` method will choose only one image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "n1EXyPuDnywu",
    "outputId": "cf377be9-1cff-45e6-cbd4-77b4eec5c2f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images in the training set have:\n",
      "• dtype: <dtype: 'uint8'>\n",
      "• shape: (28, 28, 1)\n",
      "\n",
      "The labels of the images have:\n",
      "• dtype: <dtype: 'int64'>\n",
      "\n",
      " --------------------\n"
     ]
    }
   ],
   "source": [
    "# .take(2) consider two images. we can see different images by using different numbers in take(number)\n",
    "# image and label are both tensor\n",
    "for image, label in training_set.take(1):\n",
    "    print('The images in the training set have:')\n",
    "    print('\\u2022 dtype:', image.dtype) \n",
    "    print('\\u2022 shape:', image.shape)\n",
    "  \n",
    "    print('\\nThe labels of the images have:')\n",
    "    print('\\u2022 dtype:', label.dtype) \n",
    "    print('\\n --------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gcgow6H54ujJ"
   },
   "source": [
    "The images in our dataset are tensors of `shape = (28, 28, 1)` and `dtype = uint8`. `unit8` represents an 8-bit unsigned integer and can hold integers in the range 0 to 255. On the other hand, the labels of our images are tensors of `dtype = int64`, which means they are 64-bit signed integers. Now let's see what an image from our dataset looks like. In order to plot our images, we will have to convert them from TensorFlow tensors to NumPy ndarrays first, by using the `.numpy()` method. Since the images have `shape = (28, 28, 1)` we will use the `.squeeze()` method to reshape the images to have `shape = (28, 28)`. The `.squeeze()` method removes single-dimensional entries from the shape of an ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "z7MooIVjn34f",
    "outputId": "ac9862fb-7f61-426e-c52d-bbf64ebc5c80"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 305
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of this image is: 0\n"
     ]
    }
   ],
   "source": [
    "for image, label in training_set.take(1):\n",
    "    image = image.numpy().squeeze() # image and label are both tensor and we need to change their type to numpy first here\n",
    "    label = label.numpy()\n",
    "    \n",
    "# Plot the image\n",
    "plt.imshow(image, cmap = plt.cm.binary) # binary color becuase we are ploting in gray scale.\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "# pay attention the scale of the plot in the x axis and y axis is 28 by 28 and the gray scale is from 0 to 255\n",
    "# in the next part when we do normalization you will see this scale will change \n",
    "print('The label of this image is:', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJkmaOsyYpOz"
   },
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5emVveHn7X6"
   },
   "source": [
    "As we can see, the pixel values of our images are in the range `[0, 255]`. We will now normalize the images and create a pipeline with our training set so that it can be fed into our neural network. In order to normalize the images we are going to divide the pixel values by 255. We will therefore, first change the `dtype` of our image from `uint8` to `float32`  (32-bit single-precision floating-point numbers) using the `tf.cast` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3g_jqq96n8Ft"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwe want to start conducting our pipline on our training set:\\n\\n1.\\t.cache() the cache method move our dataset to our memory for quick access. Note you should only use cache method if you \\nhave enough memroy to fit your dataset. Here we are using MNIST dataset which is pretty small and you can fit it in \\nthe memory of most computers however other dataset may have the size of GIGA size so they are too large to fit in \\nthe available memory of your dataset.\\n\\n2.\\tshuffle(num_training_examples//4). The second transformation we are going to apply is shuffle method. Ths shuffle \\ntransformation randomly shuffled images in our dataset before fitting in neural network. This is for preventing the \\nnetwork for memorizing the data. Shuffle takes one argument which represent the number of images we want to shuffle.  \\nThis is also called ‘buffer size’, you can shuffle all the dataset or you can shuffle the fraction of them. \\nThe reason we  do not shuffle the entire dataset because we want to increase our training efficiency. \\nBecause shuffle happen at every iteration and if we want to shuffle all 60 thousand images in each iteration it takes time. \\nSo as you can see here we shuffle only random subset of training set. As with all of the other transformation method you \\ncan play with different parameters to find the best accuracy and speed balance.(for example which shuffel parameter give \\nyou the best accuracy and speed balance).\\n\\n\\n3.\\t.batch(batch_size): next transformation here we use is the batch method. It takes the batch size is number of data \\nwe give to our neural netwrok in every iteration. Here we define batchsize as 64. But you can use different size too \\nand also you can experiment different batch sizes and measure the accuracy and speed balance.\\n\\n4.\\t.map(normalize): We use map transformation to apply normalize function that we define before.\\n\\nHow we normalize images:?\\nAs you remember pixel values in images range from 0 to 255. We want to normalize our pixel value to range from 0 to 1.\\nThis normalizition help algoritm converge easier faster.\\n\\n\\ndef normalize(image, label):\\n    image = tf.cast(image, tf.float32) # with this cast method we can change the data type\\n                                         but when we change the value from 0 to 255 to 0 to 1 we need to change the \\n                                         type of value from int to float too\\n    image /= 255\\n    return image, label\\n5.\\t.prefetch(1): The next method that we will use for our transformaion is prepetch. This method prepare the next batch of data while current batch is processing. In this way we eliminate the tiem that we need to process new data to get prepared for giving to neural network.\\nتوجه کن که این transformation هایی که بالا ذکر شد خیلی ترتیب شون ضروری نیست بلکه میتونن در ترتیب دیگه ای هم انجام بشن اما نکته مهم اینه که \\nThe ordering of some certain transformation has perfromance implication.\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Pipeline: means do some transformation on data that help them be prepared to feed into neural network.\n",
    "def normalize(image, label):\n",
    "    image = tf.cast(image, tf.float32) #tf.cast help to change the datatype.\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "training_batches = training_set.cache().shuffle(num_training_examples//4).batch(batch_size).map(normalize).prefetch(1)\n",
    "\n",
    "'''\n",
    "we want to start conducting our pipline on our training set:\n",
    "\n",
    "1.\t.cache() the cache method move our dataset to our memory for quick access. Note you should only\n",
    "use cache method if you have enough memroy to fit your dataset. Here we are using MNIST dataset\n",
    "which is pretty small and you can fit it in the memory of most computers however other dataset \n",
    "may have the size of GIGA size so they are too large to fit in the available memory of your dataset.\n",
    "\n",
    "2.\tshuffle(num_training_examples//4). The second transformation we are going to apply is shuffle\n",
    "method. Ths shuffle transformation randomly shuffled images in our dataset before fitting in \n",
    "neural network. This is for preventing the network for memorizing the data. Shuffle takes one\n",
    "argument which represent the number of images we want to shuffle.  This is also called ‘buffer size’,\n",
    "you can shuffle all the dataset or you can shuffle the fraction of them. The reason we  do not\n",
    "shuffle the entire dataset because we want to increase our training efficiency. \n",
    "Because shuffle happen at every iteration and if we want to shuffle all 60 thousand images in each\n",
    "iteration it takes time. So as you can see here we shuffle only random subset of training set.\n",
    "As with all of the other transformation method you can play with different parameters to find\n",
    "the best accuracy and speed balance.(for example which shuffel parameter give \n",
    "you the best accuracy and speed balance).\n",
    "\n",
    "\n",
    "3.\t.batch(batch_size): next transformation here we use is the batch method. It takes the batch size\n",
    "is number of data we give to our neural netwrok in every iteration. Here we define batchsize as 64.\n",
    "But you can use different size too and also you can experiment different batch sizes and measure the\n",
    "accuracy and speed balance.\n",
    "\n",
    "4.\t.map(normalize): We use map transformation to apply normalize function that we define before.\n",
    "\n",
    "How we normalize images:?\n",
    "As you remember pixel values in images range from 0 to 255. We want to normalize our pixel value to\n",
    "range from 0 to 1.This normalizition help algoritm converge easier faster.\n",
    "\n",
    "\n",
    "def normalize(image, label):\n",
    "    image = tf.cast(image, tf.float32) # with this cast method we can change the data type\n",
    "                                         but when we change the value from 0 to 255 to 0 to 1 we need to change the \n",
    "                                         type of value from int to float too\n",
    "    image /= 255\n",
    "    return image, label\n",
    "5.\t.prefetch(1): The next method that we will use for our transformaion is prepetch. \n",
    "This method prepare the next batch of data while current batch is processing. \n",
    "In this way we eliminate the tiem that we need to process new data to get prepared for \n",
    "giving to neural network.\n",
    "توجه کن که این transformation هایی که بالا ذکر شد خیلی ترتیب شون ضروری نیست بلکه میتونن در ترتیب دیگه ای هم انجام بشن اما نکته مهم اینه که \n",
    "The ordering of some certain transformation has perfromance implication.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AXQPznKeoBcx"
   },
   "source": [
    "You'll notice we created the pipeline with a batch size of `64`, and that we are shuffling our dataset. The batch size is the number of images we get in one iteration and are passed through our network, often called a *batch*. The `shuffle` transformation randomly shuffles the elements of our dataset before being fed to our network.\n",
    "\n",
    "Although many of these transformations are commutative, the ordering of certain transformations has performance implications. For more information on these transformations and their impact on performance make sure to check the following links:\n",
    "\n",
    "* [Pipeline Performance](https://www.tensorflow.org/beta/guide/data_performance)\n",
    "\n",
    "\n",
    "* [Transformations](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)\n",
    "\n",
    "Now that we have our `training_batches` let's inspect them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Yh3fw8YvoB_N",
    "outputId": "92cbef35-7d51-40ed-dedd-dd90ccd41fc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images in each batch have:\n",
      "• dtype: <dtype: 'float32'>\n",
      "• shape: (64, 28, 28, 1)\n",
      "\n",
      "There are a total of 64 image labels in this batch:\n",
      "[3 4 0 7 5 2 3 8 0 7 4 1 9 5 0 9 2 9 9 6 1 0 3 9 0 0 6 6 7 2 3 9 7 3 9 8 4\n",
      " 7 6 0 4 7 0 3 4 9 3 6 4 8 9 4 7 0 0 5 6 6 8 9 9 0 5 6]\n"
     ]
    }
   ],
   "source": [
    "# training_batches include batches and each batches include 64 images and labels\n",
    "# so even when we use .take(1) in training_batches we have 64 images\n",
    "for image_batch, label_batch in training_batches.take(1):\n",
    "    print('The images in each batch have:')\n",
    "    print('\\u2022 dtype:', image_batch.dtype) \n",
    "    print('\\u2022 shape:', image_batch.shape)\n",
    "  \n",
    "    print('\\nThere are a total of {} image labels in this batch:'.format(label_batch.numpy().size))\n",
    "    print(label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BKyE_NeNoGo5"
   },
   "source": [
    "Now, let's see how we can grab a single image from our one of our batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "Td2-DArEoHHu",
    "outputId": "c62e7df4-42bb-41e6-9576-cab6f796680d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 252,
       "width": 302
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of this image is: 8\n"
     ]
    }
   ],
   "source": [
    "# Take a single batch of images, and remove the color dimension by squeezing it\n",
    "for image_batch, label_batch in training_batches.take(1):\n",
    "    # agin we need to convert images and labels to numpy to be able to plot them. here the size of images in (64,28,28,1)\n",
    "    # by squeezing we omit 1 but we still have 64 images\n",
    "    images = image_batch.numpy().squeeze() \n",
    "    labels = label_batch.numpy()\n",
    "\n",
    "# Plot the image\n",
    "# so we choose one image from 64 images by image[0]\n",
    "plt.imshow(images[0], cmap = plt.cm.binary) \n",
    "# but here in training_batches has 64 images so we need select only one of them images[0]\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print('The label of this image is:', labels[0])\n",
    "# as you can see here the plot x axis and y axis is go from 0 to 28 here like traininset but\n",
    "# the gray scale here is between 0 to 1 in contrast to gray scale in training set which was from 0 to 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aa2qHmjUoMNS"
   },
   "source": [
    "## Build a Simple Neural Network\n",
    "\n",
    "First, let's try to build a simple network for this dataset using weight matrices and matrix multiplications, just like we did in the previous notebook. Then, we'll see how to do it using TensorFlow and Keras, which provides a much more convenient and powerful method for defining network architectures.\n",
    "\n",
    "The networks you've seen so far are called *fully-connected* or *dense* networks. Each unit in one layer is connected to each unit in the next layer. In fully-connected networks, the input to each layer must be a one-dimensional vector (which can be stacked into a 2D tensor as a batch of multiple examples). However, our images are 28 $\\times$ 28 2D tensors, so we need to convert them into 1D vectors. Thinking about sizes, we need to convert the batch of images with shape `(64, 28, 28, 1)` to a have a shape of `(64, 784)`, 784 is 28 times 28. This is typically called *flattening*, we flattened the 2D images into 1D vectors.\n",
    "\n",
    "In the previous notebook, you built a network with one output unit. Here we need 10 output units, one for each digit. We want our network to predict the digit shown in an image, so what we'll do, is calculate the probabilities that the image is of any one digit or class. This ends up being a discrete probability distribution over the classes (digits) that tells us the most likely class for the image. That means we need 10 output units for the 10 classes (digits). We'll see how to convert the network output into a probability distribution next.\n",
    "\n",
    "> **Exercise:** Flatten the batch of images `images` that we've created above. Then build a simple network with 784 input units, 256 hidden units, and 10 output units using random tensors for the weights and biases. For now, use a sigmoid activation function for the units in the hidden layer. Leave the output layer without an activation, we'll add one that gives us a probability distribution next. **HINT:** You can use the [`tf.reshape()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/reshape) function to flatten the batch of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "69pQ7bEIoMw0",
    "outputId": "edc086d3-29a3-456e-a997-07174c31d87b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs have shape: (64, 784)\n",
      "The output has shape: (64, 10)\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "def activation(x):\n",
    "    \"\"\" Sigmoid activation function\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        x: tf.Tensor. Must be one of the following types: bfloat16, half, float32, float64, complex64, complex128.\n",
    "    \"\"\"\n",
    "    return 1/(1+tf.exp(-x))\n",
    "\n",
    "# Flatten the input images\n",
    "# if you remembere in the previous part we change the images from tesnor of (64,28,28,1) to numpy array (64,28,28)\n",
    "# here we want to flatten the numpy array but we wnat to keep the number of batches 64 so for the first diemsnion \n",
    "# we say images.shape[0] and for the second dimension we say -1. this -1 tell multiply the left dimension. so here we define \n",
    "# the firts dimesnion as 64 and still we need to define the other dimesnion so this -1 tell the algoritm to do so\n",
    "# 28* 28=784\n",
    "inputs = tf.reshape(images, [images.shape[0], -1])\n",
    "\n",
    "# Print the shape of the inputs. Should be (64,784)\n",
    "print('The inputs have shape:', inputs.shape)\n",
    "\n",
    "# Create Neural Network parameters\n",
    "w1 = tf.random.normal((784,256))\n",
    "b1 = tf.random.normal((1,256))\n",
    "\n",
    "w2 = tf.random.normal((256,10))\n",
    "b2 = tf.random.normal((1,10))\n",
    "\n",
    "# Perform matrix multiplications for the hidden layer\n",
    "# and apply activation function\n",
    "h = activation(tf.matmul(inputs, w1) + b1)\n",
    "\n",
    "# Perform matrix multiplication for the output layer\n",
    "output = tf.matmul(h, w2) + b2\n",
    "\n",
    "# Print the shape of the output. It should be (64,10)\n",
    "print('The output has shape:', output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6YnpZowoSz2"
   },
   "source": [
    "Now we have 10 outputs for our network. We want to pass in an image to our network and get out a probability distribution over the classes that tells us the most likely class(es) the image belongs to. Something that looks like this:\n",
    "<img src='assets/image_distribution.png' width=500px>\n",
    "\n",
    "Here we see that the probability for each class is roughly the same. This is representing an untrained network, it hasn't seen any data yet so it just returns a uniform distribution with equal probabilities for each class.\n",
    "\n",
    "To calculate this probability distribution, we often use the [**softmax** function](https://en.wikipedia.org/wiki/Softmax_function). Mathematically this looks like\n",
    "\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "\n",
    "What this does is squish each input $x_i$ between 0 and 1 and normalizes the values to give you a proper probability distribution where the probabilities sum up to one.\n",
    "\n",
    "> **Exercise:** Implement a function `softmax` that performs the softmax calculation and returns probability distributions for each example in the batch. Note that you'll need to pay attention to the shapes when doing this. If you have a tensor `a` with shape `(64, 10)` and a tensor `b` with shape `(64,)`, doing `a/b` will give you an error because TensorFlow will try to do the division across the columns (called broadcasting) but you'll get a size mismatch. The way to think about this is the following: for each of the 64 examples, you only want to divide by one value, the sum in the denominator. So you need `b` to have a shape of `(64, 1)`. This way TensorFlow will divide the 10 values in each row of `a` by the one value in each row of `b`. Pay attention to how you take the sum as well. You'll need to define the `axis` keyword in `tf.reduce_sum()`. Setting `axis=0` takes the sum across the rows while `axis=1` takes the sum across the columns. You will also need to use the `keepdims` keyword in `tf.reduce_sum()` to make sure the output tensor has the correct shape `(64,1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mPtaB817oTTe",
    "outputId": "cada472f-7d69-4581-9d63-d8d62f2f9830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs have shape: (64, 784)\n",
      "The output has shape: (64, 10)\n",
      "The probabilities have shape: (64, 10) \n",
      "\n",
      "Sum of probabilities for Image 1: 1.0\n",
      "Sum of probabilities for Image 2: 1.0\n",
      "Sum of probabilities for Image 3: 1.0\n",
      "Sum of probabilities for Image 4: 1.0\n",
      "Sum of probabilities for Image 5: 1.0\n",
      "Sum of probabilities for Image 6: 1.0\n",
      "Sum of probabilities for Image 7: 1.0\n",
      "Sum of probabilities for Image 8: 1.0\n",
      "Sum of probabilities for Image 9: 1.0\n",
      "Sum of probabilities for Image 10: 1.0\n",
      "Sum of probabilities for Image 11: 1.0\n",
      "Sum of probabilities for Image 12: 1.0\n",
      "Sum of probabilities for Image 13: 1.0\n",
      "Sum of probabilities for Image 14: 1.0\n",
      "Sum of probabilities for Image 15: 1.0\n",
      "Sum of probabilities for Image 16: 1.0\n",
      "Sum of probabilities for Image 17: 1.0\n",
      "Sum of probabilities for Image 18: 1.0\n",
      "Sum of probabilities for Image 19: 1.0\n",
      "Sum of probabilities for Image 20: 1.0\n",
      "Sum of probabilities for Image 21: 1.0\n",
      "Sum of probabilities for Image 22: 1.0\n",
      "Sum of probabilities for Image 23: 1.0\n",
      "Sum of probabilities for Image 24: 1.0\n",
      "Sum of probabilities for Image 25: 1.0\n",
      "Sum of probabilities for Image 26: 1.0\n",
      "Sum of probabilities for Image 27: 1.0\n",
      "Sum of probabilities for Image 28: 1.0\n",
      "Sum of probabilities for Image 29: 1.0\n",
      "Sum of probabilities for Image 30: 1.0\n",
      "Sum of probabilities for Image 31: 1.0\n",
      "Sum of probabilities for Image 32: 1.0\n",
      "Sum of probabilities for Image 33: 1.0\n",
      "Sum of probabilities for Image 34: 1.0\n",
      "Sum of probabilities for Image 35: 1.0\n",
      "Sum of probabilities for Image 36: 1.0\n",
      "Sum of probabilities for Image 37: 1.0\n",
      "Sum of probabilities for Image 38: 1.0\n",
      "Sum of probabilities for Image 39: 1.0\n",
      "Sum of probabilities for Image 40: 1.0\n",
      "Sum of probabilities for Image 41: 1.0\n",
      "Sum of probabilities for Image 42: 1.0\n",
      "Sum of probabilities for Image 43: 1.0\n",
      "Sum of probabilities for Image 44: 1.0\n",
      "Sum of probabilities for Image 45: 1.0\n",
      "Sum of probabilities for Image 46: 1.0\n",
      "Sum of probabilities for Image 47: 1.0\n",
      "Sum of probabilities for Image 48: 1.0\n",
      "Sum of probabilities for Image 49: 1.0\n",
      "Sum of probabilities for Image 50: 1.0\n",
      "Sum of probabilities for Image 51: 1.0\n",
      "Sum of probabilities for Image 52: 1.0\n",
      "Sum of probabilities for Image 53: 1.0\n",
      "Sum of probabilities for Image 54: 1.0\n",
      "Sum of probabilities for Image 55: 1.0\n",
      "Sum of probabilities for Image 56: 1.0\n",
      "Sum of probabilities for Image 57: 1.0\n",
      "Sum of probabilities for Image 58: 1.0\n",
      "Sum of probabilities for Image 59: 1.0\n",
      "Sum of probabilities for Image 60: 1.0\n",
      "Sum of probabilities for Image 61: 1.0\n",
      "Sum of probabilities for Image 62: 1.0\n",
      "Sum of probabilities for Image 63: 1.0\n",
      "Sum of probabilities for Image 64: 1.0\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "def activation(x):\n",
    "    \"\"\" Sigmoid activation function\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        x: tf.Tensor. Must be one of the following types: bfloat16, half, float32, float64, complex64, complex128.\n",
    "    \"\"\"\n",
    "    return 1/(1+tf.exp(-x))\n",
    "\n",
    "inputs = tf.reshape(images, [images.shape[0], -1])\n",
    "\n",
    "# Print the shape of the inputs. Should be (64,784)\n",
    "print('The inputs have shape:', inputs.shape)\n",
    "\n",
    "# Create Neural Network parameters\n",
    "w1 = tf.random.normal((784,256))\n",
    "b1 = tf.random.normal((1,256))\n",
    "\n",
    "w2 = tf.random.normal((256,10))\n",
    "b2 = tf.random.normal((1,10))\n",
    "\n",
    "# Perform matrix multiplications for the hidden layer\n",
    "# and apply activation function\n",
    "h = activation(tf.matmul(inputs, w1) + b1)\n",
    "\n",
    "# Perform matrix multiplication for the output layer\n",
    "output = tf.matmul(h, w2) + b2\n",
    "\n",
    "# Print the shape of the output. It should be (64,10)\n",
    "print('The output has shape:', output.shape)\n",
    "\n",
    "def softmax(x):\n",
    "     \n",
    "    return tf.exp(x) / tf.reduce_sum(tf.exp(x), axis=1, keepdims=True)\n",
    "\n",
    "# Apply softmax to the output\n",
    "probabilities = softmax(output)\n",
    "\n",
    "# Print the shape of the probabilities. Should be (64, 10).\n",
    "print('The probabilities have shape:', probabilities.shape, '\\n')\n",
    "\n",
    "\n",
    "# The sum of probabilities for each of the 64 images should be 1\n",
    "# here we sum up the probability of each row in the matrix of 64*10 . it means we wnat to sum up the probability for each image\n",
    "# that should all sum up to one. for xample image 1 show the probability 0.01 for class 0 show the probability 0.02 for class 1\n",
    "# and so on so forth\n",
    "sum_all_prob = tf.reduce_sum(probabilities, axis = 1).numpy() \n",
    "\n",
    "# Print the sum of the probabilities for each image.\n",
    "for i, prob_sum in enumerate(sum_all_prob):\n",
    "    print('Sum of probabilities for Image {}: {:.1f}'.format(i+1, prob_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmUrxgU5dK3w"
   },
   "source": [
    "## Building Neural Networks with TensorFlow and Keras\n",
    "\n",
    "Keras is a high-level API to build and train neural networks. `tf.keras` is TensorFlow's implementation of the Keras API. In Keras, deep learning models are constructed by connecting configurable building blocks called **layers**. The most common type of model is a stack of layers called a **Sequential** model. The model is called sequential because it allows a tensor to be passed sequentially through the operations in each layer. In TensorFlow, the sequential model is implemented with `tf.keras.Sequential`. \n",
    "\n",
    "In the cell below, we will use a Keras sequential model to build the same fully-connected neural network that we built in the previous section. Our sequential model will have three layers:\n",
    "\n",
    "* **Input Layer:** `tf.keras.layers.Flatten` — This layer flattens the images by transforming a 2d-array of 28 $\\times$ 28 pixels, to a 1d-array of 784 pixels (28 $\\times$ 28 = 784). The first layer in a Sequential model needs to know the shape of the input tensors to the model. Since, this is our first layer, we need to specify the shape of our input tensors using the `input_shape` argument. The `input_shape` is specified using a tuple that contains the size of our images and the number of color channels. It is important to note that we don't have to include the batch size in the tuple. The tuple can have integers or `None` entries, where `None` entries indicate that any positive integer may be expected.\n",
    "\n",
    "* **Hidden Layer:** `tf.keras.layers.Dense` — A fully-connected (also known as densely connected) layer. For this layer we need to specify the number of neurons (or nodes) we want to use and the activation function. Note that we don't have to specify the shape of the input tensor to this layer, since Keras performs automatic shape inference for all layers except for the first layer. In this particular case, we are going to use `256` neurons with a `sigmoid` activation fucntion. \n",
    "\n",
    "* **Output Layer:** `tf.keras.layers.Dense` — A fully-connected layer with 10 neurons and a *softmax* activation function. The output values will represent the probability that the image is a particular digit. The sum of all the 10 nodes values is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "tujWgGJ1emo_",
    "outputId": "26949733-4eb1-4f57-9d70-a2e39281d755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# it gives back us the model name, type of layers their shape and number of parameters in each layer\\n# the None in the output shape column shows that they can accept any batch size. we did not \\n  define batch size here\\n# but it can accept any batch_size (the only things is batch size needs to be positive int)\\n\\n# the collumn parameters refer to the number of weights and biases in each layer.\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "we need to specify the input dimension for the first layer in the Sequential model by a tuple of \n",
    "size of the image and color channels. input-shape(28,28,1) 28*28 is the size of image and 1 \n",
    "is the color channel because we have only gray scale here the color channel is 1\n",
    "'''\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape = (28,28,1)),  \n",
    "    # only for the first layer in Sequential model we need to mention \n",
    "    # the number of inputs\n",
    "    # this flatten layer flat the image by itself so we do not to be worry \n",
    "    # about flattening the image\n",
    "    \n",
    "        tf.keras.layers.Dense(256, activation = 'sigmoid'),\n",
    "    # for other layers we do not need to mention the number of layers but \n",
    "    # we need to mention the number of nodes and type of activation function\n",
    "        tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "# we can use .summary() method to get some information about our model architucteure\n",
    "model.summary()\n",
    "'''\n",
    "# it gives back us the model name, type of layers their shape and number of parameters in each layer\n",
    "# the None in the output shape column shows that they can accept any batch size. we did not \n",
    "  define batch size here\n",
    "# but it can accept any batch_size (the only things is batch size needs to be positive int)\n",
    "\n",
    "# the collumn parameters refer to the number of weights and biases in each layer.\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I like to make a note hear that when we make or use Sequential model it is not really flexiable.\n",
    " there are other ways to make the model more flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AGqf8FCZ1bAs"
   },
   "source": [
    "### Your Turn to Build a Neural Network\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "> **Exercise:** Create a network with 784 input units, a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and finally an output layer with 10 units and a softmax activation function. You can use a ReLU activation function by setting `activation = 'relu'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "l-s_J0NC1jdH",
    "outputId": "47ce3f16-a287-44df-a0fd-015a5601f29f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "my_model_1 = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape = (28,28,1)), # i think i can give input like this too\n",
    "                                                          # input_shape(None, 784) \n",
    "                                                          # None is the number of batch size and \n",
    "                                                          # it can be any positive int\n",
    "        tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "my_model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdBvHoq5jnkt"
   },
   "source": [
    "## Activation Functions\n",
    "\n",
    "So far we've only been looking at the softmax activation, but in general any function can be used as an activation function. The only requirement is that for a network to approximate a non-linear function, the activation functions must be non-linear. Here are a few more examples of common activation functions: Tanh (hyperbolic tangent), and ReLU (rectified linear unit).\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "In practice, the ReLU function is used almost exclusively as the activation function for hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "79odRUgEj8_e"
   },
   "source": [
    "## Looking at the Weights and Biases\n",
    "\n",
    "Keras automatically initializes the weights and biases. The weights and biases are tensors attached to each of the layers you defined in your model. We can get all the weights and biases from our model by using the `get_weights` method. The `get_weights` method returns a list of all the weight and bias tensors in our model as NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DxZlaMjwe-Lk",
    "outputId": "9992e8d6-0874-49d0-d01c-ab0f21a6c5f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "model_weights_biases = model.get_weights()\n",
    "\n",
    "print(type(model_weights_biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "Zktwcu9ZfAsT",
    "outputId": "ebd43ad2-06ee-4d75-a14e-c1f5f18f236e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 4 NumPy ndarrays in our list\n",
      "\n",
      "[array([[-0.07028517,  0.0327006 , -0.05877179, ...,  0.01565402,\n",
      "        -0.03827714, -0.0358993 ],\n",
      "       [ 0.05164647,  0.05867982,  0.05247805, ..., -0.03058749,\n",
      "        -0.04352426, -0.04753179],\n",
      "       [ 0.04727201,  0.0189921 ,  0.04550977, ..., -0.02803764,\n",
      "         0.05493213,  0.06499684],\n",
      "       ...,\n",
      "       [-0.04132365,  0.06593324,  0.05790102, ...,  0.02071945,\n",
      "        -0.02768209, -0.03924359],\n",
      "       [ 0.03892247,  0.05988269, -0.00835028, ...,  0.06721628,\n",
      "        -0.06944962, -0.04185873],\n",
      "       [ 0.02418979, -0.02826892, -0.04126818, ..., -0.05969945,\n",
      "         0.0744254 , -0.00570559]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32), array([[-0.07970401, -0.12024724,  0.14531723, ...,  0.12248781,\n",
      "        -0.15004133,  0.00989117],\n",
      "       [ 0.02177472, -0.03809048,  0.11881688, ...,  0.03103951,\n",
      "        -0.01825145, -0.02552543],\n",
      "       [ 0.0961723 , -0.09470494,  0.11373529, ...,  0.03122485,\n",
      "        -0.14708498, -0.13620348],\n",
      "       ...,\n",
      "       [ 0.08718918,  0.1119228 , -0.02170469, ..., -0.05007317,\n",
      "         0.01660322, -0.08472043],\n",
      "       [-0.08175818,  0.09043449, -0.11612669, ...,  0.00967285,\n",
      "         0.01790579, -0.00746101],\n",
      "       [-0.09188829,  0.04501098, -0.12609662, ..., -0.07517567,\n",
      "        -0.07411194, -0.10938071]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print('\\nThere are {:,} NumPy ndarrays in our list\\n'.format(len(model_weights_biases)))\n",
    "\n",
    "print(model_weights_biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEOFFR8Yi829"
   },
   "source": [
    "We can also get the weights and biases for a specific layer by using the `get_layer` method. In this case we first specify the layer we want by using the `index` argument and the apply the `get_weights` method as we did before. For example, to get the weights and biases of the first layer of our sequential model we will use:\n",
    "index define which layer. here index=0 shows first layer\n",
    "\n",
    "```python\n",
    "weights = model.get_layer(index=0).get_weights()[0]\n",
    "biases = model.get_layer(index=0).get_weights()[1]\n",
    "\n",
    "```\n",
    "\n",
    "Notice, that we used `index=0` to get the first layer of our model which in this case is a `tf.keras.layers.Flatten`. Since this layer just flattens our input, it has no weights or biases. Therefore, in this case, the layer with `index=0` has no weights or biases, so calling `get_weights()[0]` will produce an error because  `get_weights()` will return an empty list (`[]`). So, when you are getting the weights and biases from each layer you should check first whether the layer has any weights or biases at all. \n",
    "\n",
    "Alternatively, you can also use the `layers` method to get a list of the layers of your model. You can then loop through the layers and check if they have weights before calling `get_weights()`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "tcWGSl2rhMif",
    "outputId": "84d94a15-3dec-4567-8bba-874ffdbd0c7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Flatten at 0x29ec40fa9e8>,\n",
       " <keras.layers.core.Dense at 0x29ec4230128>,\n",
       " <keras.layers.core.Dense at 0x29ec4230438>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dislay the layers in our model\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x29ec4230748>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Lw1M2CWmfDU3",
    "outputId": "0e3ad837-4ecc-42c5-e10f-12b28635acb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 0: flatten\n",
      "\n",
      "This layer has no weights or biases.\n",
      "\n",
      "------------------------\n",
      "\n",
      "Layer 1: dense\n",
      "\n",
      "• Weights:\n",
      " [[ 0.05224116  0.06571884 -0.04375715 ...  0.02187659  0.04687703\n",
      "   0.03914039]\n",
      " [ 0.05805588 -0.03016243  0.06498681 ...  0.00293887  0.01537188\n",
      "  -0.03088053]\n",
      " [-0.0175484   0.05299486 -0.05896376 ... -0.05301232  0.05598871\n",
      "   0.0562644 ]\n",
      " ...\n",
      " [-0.0278205  -0.02363378  0.03063794 ...  0.06159528  0.01429632\n",
      "   0.05626869]\n",
      " [ 0.0559631  -0.05457924 -0.05597868 ... -0.0731673   0.05408156\n",
      "  -0.037999  ]\n",
      " [ 0.02459992  0.06444438  0.06747225 ...  0.06128664 -0.06186411\n",
      "   0.07071055]]\n",
      "\n",
      "• Biases:\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "This layer has a total of 200,704 weights and 256 biases\n",
      "\n",
      "------------------------\n",
      "\n",
      "Layer 2: dense_1\n",
      "\n",
      "• Weights:\n",
      " [[ 0.02185465 -0.05030233 -0.1368684  ... -0.00501524  0.07895398\n",
      "   0.08419384]\n",
      " [-0.05298693  0.09776023 -0.09744956 ...  0.0623804   0.08589235\n",
      "   0.06363741]\n",
      " [-0.08758185  0.01470761  0.01309179 ...  0.04968333 -0.1081176\n",
      "  -0.0717071 ]\n",
      " ...\n",
      " [ 0.05959898 -0.06248511 -0.01243587 ... -0.05505529  0.10256878\n",
      "  -0.1342663 ]\n",
      " [ 0.02986807 -0.07544731 -0.09657618 ...  0.04134127  0.04379578\n",
      "  -0.018751  ]\n",
      " [-0.13206592  0.07676896  0.09197329 ...  0.02362734 -0.1323594\n",
      "   0.09826794]]\n",
      "\n",
      "• Biases:\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "This layer has a total of 2,560 weights and 10 biases\n",
      "\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    \n",
    "    if len(layer.get_weights()) > 0:\n",
    "        w = layer.get_weights()[0]\n",
    "        b = layer.get_weights()[1]\n",
    "        \n",
    "        print('\\nLayer {}: {}\\n'.format(i, layer.name))\n",
    "        print('\\u2022 Weights:\\n', w)\n",
    "        print('\\n\\u2022 Biases:\\n', b)\n",
    "        print('\\nThis layer has a total of {:,} weights and {:,} biases'.format(w.size, b.size))\n",
    "        print('\\n------------------------')\n",
    "    \n",
    "    else:\n",
    "        print('\\nLayer {}: {}\\n'.format(i, layer.name))\n",
    "        print('This layer has no weights or biases.')\n",
    "        print('\\n------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t8TbtpkxGImY"
   },
   "source": [
    "As we can see, by default, all the biases are initialized to zero.\n",
    "\n",
    "On the other hand, by default, the weights are initialized using a Glorot uniform initializer that draws samples from a uniform distribution within \\[-`limit`, `limit`\\] where `limit` is `sqrt(6 / (fan_in + fan_out))` where `fan_in` is the number of input units in the weight tensor and `fan_out` is the number of output units in the weight tensor.\n",
    "\n",
    "In Keras, you can change the default initialization methods for the weights and biases. To know more about the available initializers check out the links below:\n",
    "\n",
    "* [Available initializers](https://keras.io/initializers/)\n",
    "\n",
    "* [Dense Layer](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tyHIkuwBkFTK"
   },
   "source": [
    "## Make Predictions\n",
    "\n",
    "To make predictions on a batch of images with our model we use the `.predict(image_batch)` method. This method takes the images in our batch, feeds them to our network, performs a forward pass, and outputs a NumPy ndarray of shape `(batch_size, num_classes)` with the predicted probabilities for each image in the batch. \n",
    "\n",
    "Since we have 64 images per batch (*i.e.* `batch_size = 64`) and our dataset has 10 classes (*i.e.* `num_classes = 10`), then our model will output an array of shape `(64,10)`. The rows in this array hold the predicted probabilities for our images. Consequently, the first row holds the predicted probabilities for the first image in our batch; the second row holds the predicted probabilities for the second image in our batch; the third row holds the predicted probabilities for the third image in our batch; and so on. In this case, the predicted probabilities consist of 10 values, that is, one probability per class. Therefore, for each of the 64 images in our batch we will have 10 probabilities. \n",
    "\n",
    "Let's plot our model's predicted probabilities for the first image in our batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "MHMK-x15ju84",
    "outputId": "bac86697-a9d9-4a67-9166-ef53a8e33b2b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 235,
       "width": 424
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image_batch, label_batch in training_batches.take(1):\n",
    "    ps = model.predict(image_batch) # ps contain the probability for each image in the batch since we 64 images then we have\n",
    "                                    # (64,10) dimension for ps\n",
    "    first_image = image_batch.numpy().squeeze()[0]\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "ax1.imshow(first_image, cmap = plt.cm.binary)\n",
    "ax1.axis('off')\n",
    "ax2.barh(np.arange(10), ps[0]) # we use ps[0] to see the prdicited probability only for the first image in the batch\n",
    "ax2.set_aspect(0.1)\n",
    "ax2.set_yticks(np.arange(10))\n",
    "ax2.set_yticklabels(np.arange(10))\n",
    "ax2.set_title('Class Probability')\n",
    "ax2.set_xlim(0, 1.1)\n",
    "plt.tight_layout()\n",
    "# as you can see we could not find good probability for the image since we have not traind our data yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nez7TYqwjzN0"
   },
   "source": [
    "As you can see above, our model gives every digit roughly the same probability. This means our network has basically no idea what the digit in the image is. This is because we haven't trained our model yet, so all the weights are random!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras Python library makes creating deep learning models fast and easy.\n",
    "\n",
    "The sequential API allows you to create models layer-by-layer for most problems. It is limited in that it does not allow you to create models that share layers or have multiple inputs or outputs.\n",
    "\n",
    "The functional API in Keras is an alternate way of creating models that offers a lot more flexibility, including creating more complex models.\n",
    "\n",
    "In this tutorial, you will discover how to use the more flexible functional API in Keras to define deep learning models.\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "\n",
    "The difference between the Sequential and Functional APIs.\n",
    "How to define simple Multilayer Perceptron, Convolutional Neural Network, and Recurrent Neural Network models using the functional API.\n",
    "How to define more complex models with shared layers and multiple inputs and outputs.\n",
    "\n",
    "click the link to have full description of functional API keras\n",
    "https://machinelearningmastery.com/keras-functional-api-deep-learning/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHUlGgapoZvf"
   },
   "source": [
    "## Subclassing with TensorFlow and Keras\n",
    "\n",
    "The `tf.keras.Sequential` model is a simple stack of layers that cannot be used to create arbitrary models. Luckily, `tf.keras` gives us the flexibility to build fully-customizable models by subclassing the `tf.keras.Model` and defining our own forward pass.\n",
    "\n",
    "In the following example we will use a subclassed `tf.keras.Model` to build the same neural network as we built above with 784 inputs, 256 hidden units, and 10 output units. As before, we will use a ReLu activation function for the units in the hidden layer, and a Softmax activation function for the output neurons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SeLyZ5_oaSz"
   },
   "outputs": [],
   "source": [
    " #here our class 'Network' inherit form 'tf.keras.Model' class. we can call our class whatever we want\n",
    "class Network(tf.keras.Model):\n",
    "    def __init__(self, num_classes = 2): # this 'num_classes = 2' define the number of unit in our output layer and we can change it\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "        # Define layers \n",
    "        # we need to define specific name for each layer\n",
    "        self.input_layer = tf.keras.layers.Flatten() # we do not need to specifiy the shape of input in the first layer here\n",
    "                                                     # but we need to define it later.\n",
    "        self.hidden_layer = tf.keras.layers.Dense(256, activation = 'relu')\n",
    "        self.output_layer = tf.keras.layers.Dense(self.num_classes, activation = 'softmax')\n",
    "    \n",
    "    # Define forward Pass\n",
    "    # the call method is where really the Sequential and Subclass method are different.\n",
    "    # this call method alow Subclassing being fully costumizable models\n",
    "    # in the call method we can specifiy all the opearion we want and the order of them like: \n",
    "    #we can do any operation on our \n",
    "    #'input-tensor'\n",
    "    # at any point. like below: we can multiply the output of hidden layer by two before feeding it to next layer\n",
    "    #     def call(self, input_tensor):\n",
    "    #    x = self.input_layer(input_tensor)\n",
    "    #   x = self.hidden_layer(x)\n",
    "    #   x=x*2\n",
    "    #   x = self.output_layer(x)\n",
    "    # so the possibility is endless and you can try as much operation as you like in the call method.\n",
    "    \n",
    "        \n",
    "    \n",
    "    def call(self, input_tensor):\n",
    "        x = self.input_layer(input_tensor)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfJjnjIvojTc"
   },
   "source": [
    "Let's go through this bit by bit.\n",
    "\n",
    "```python\n",
    "class Network(tf.keras.Model):\n",
    "```\n",
    "\n",
    "Here we're inheriting from `tf.keras.Model`. Combined with `super().__init__()` this creates a class that provides a lot of useful methods and attributes. It is mandatory to inherit from `tf.keras.Model` when you're creating a class for your network. However, the name of the class itself can be anything.\n",
    "\n",
    "We then create the layers of our network in the `__init__` method and set them as attributes of the class instance. We also assign the number of neurons in our output layer in the `__init__` method via the `num_classes` argument, which by default will have a value of 2.\n",
    "\n",
    "```python\n",
    "self.input = tf.keras.layers.Flatten()\n",
    "```\n",
    "\n",
    "The first layer flattens the input image as we have discussed previously. We have given this layer the name `self.input`. We will use this name to reference this layer later. It doesn't matter what name you give your layers, you can name them whatever you want.\n",
    "\n",
    "```python\n",
    "self.hidden = tf.keras.layers.Dense(256, activation = 'relu')\n",
    "```\n",
    "\n",
    "The second layer is a fully-connected (dense) layer with 256 neurons and a ReLu activation function. We have given this layer the name `self.hidden`. We will use this name to reference this layer later.\n",
    "\n",
    "```python\n",
    "self.output = tf.keras.layers.Dense(self.num_classes, activation = 'softmax')\n",
    "```\n",
    "\n",
    "The third and last layer (output layer) is also a fully-connected (dense) layer with `self.num_classes` neurons and a softmax activation function. By default the number of output units will be 2, but can be defined to be any other integer depending on the number of output classes of your dataset. \n",
    "\n",
    "Next, we define the forward pass in the `call` method.\n",
    "\n",
    "```python\n",
    "def call(self, input_tensor):\n",
    "```\n",
    "\n",
    "TensorFlow models created with `tf.keras.Model` must have a `call` method defined. In the `call` method we take `input_tensor` and pass it through the layers we defined in the `__init__` method.\n",
    "\n",
    "```python\n",
    "x = self.input(input_tensor)\n",
    "x = self.hidden(x)\n",
    "x = self.output(x)\n",
    "```\n",
    "\n",
    "Here the `input_tensor` is passed through each layer and reassigned to `x`. We can see that the `input_tensor` goes through the `input` layer, then the `hidden` layer, and finally through the `output` layer. The order in which you define the layers in the `__init__` method doesn't matter, but you'll need to sequence the layers correctly in the `call` method. Notice that we are referring to each layer in the `__init__` method by the name we gave them. Remember this names are arbitrary.\n",
    "\n",
    "Now that we have defined our model class we can create a `model` object. Note that we didn't specify the shape of our input tensor in our `Network` class. In this case, the weights and biases will only be initialized when we build our model by calling `build(batch_input_shape)` or when the first call to a training/evaluation method (such as `.fit` or `.evaluate`) is made. We call this a delayed-build pattern.\n",
    "\n",
    "So, now let's create a `model` object and build it (i.e. initialize its weights and biases) by calling `build()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "FZdpLsXioj_w",
    "outputId": "9b8df3b9-a258-4440-82d1-ca2f09b14232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"network\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  2570      \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a model object\n",
    "# since in this MNIST dataset we have 10 classes we put 10 here\n",
    "# here we still do not have any weights and biases since we do not provide any input_tensor\n",
    "subclassed_model = Network(10) \n",
    "\n",
    "# Build the model, i.e. initialize the model's weights and biases\n",
    "# we need to build the model by giving the input_tesor. so then we can have weights and biases\n",
    "# this None shows that accept batches of any size and we do not need to define the batch size in advance\n",
    "subclassed_model.build((None, 28, 28, 1))\n",
    "\n",
    "# print out our model summary\n",
    "subclassed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JvaGttubvdXt"
   },
   "source": [
    "Remember that `None` is used to indicate that any integer may be expected. So, we use `None` to indicate batches of any size are acceptable. \n",
    "\n",
    "While model subclassing offers flexibility, it comes at a cost of greater complexity and more opportunities for\n",
    "user errors. So, we recommend, to always use the simplest tool for the job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYc20VqXo3tm"
   },
   "source": [
    "### Your Turn to Build a Neural Network\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "> **Exercise:** Use the subclassing method to create a network with 784 input units, a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and finally an output layer with 10 units and a softmax activation function. You can use a ReLU activation function by setting `activation = 'relu'`. After you create your model, create a model object and build it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "q4FIQ-BPo1BS",
    "outputId": "ecf18a3b-192f-4b62-a64e-b4abef841080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sub_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  100480    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "class SubModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "        # Define layers \n",
    "        self.input_layer = tf.keras.layers.Flatten()\n",
    "        self.hidden_layer_1 = tf.keras.layers.Dense(128, activation = 'relu')\n",
    "        self.hidden_layer_2 = tf.keras.layers.Dense(64, activation = 'relu')\n",
    "        self.output_layer = tf.keras.layers.Dense(self.num_classes, activation = 'softmax')\n",
    "    \n",
    "    # Define forward Pass   \n",
    "    def call(self, input_tensor):\n",
    "        x = self.input_layer(input_tensor)\n",
    "        x = self.hidden_layer_1(x)\n",
    "        x = self.hidden_layer_2(x)\n",
    "        x = self.output_layer(x)\n",
    "    \n",
    "        return x \n",
    "\n",
    "my_model_2 = SubModel(10)\n",
    "my_model_2.build((None, 28, 28, 1))\n",
    "\n",
    "my_model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fau1iyME_x1M"
   },
   "source": [
    "## Looking at Weights and Biases of Subclassed Models\n",
    "\n",
    "As before, we can get the weights an biases of each layer in our subclassed models. In this case, we can use the name we gave to each layer in the `__init__` method to get the weights and biases of a particular layer. For example, in the exercise we gave the first hidden layer the name `hidden_1`, so we can get the weights an biases from this layer by using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "hdsFjbmRU_el",
    "outputId": "b3183ba2-925d-4d00-c65e-83d5980ba5a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "• Weights:\n",
      " [[ 0.02185465 -0.05030233 -0.1368684  ... -0.00501524  0.07895398\n",
      "   0.08419384]\n",
      " [-0.05298693  0.09776023 -0.09744956 ...  0.0623804   0.08589235\n",
      "   0.06363741]\n",
      " [-0.08758185  0.01470761  0.01309179 ...  0.04968333 -0.1081176\n",
      "  -0.0717071 ]\n",
      " ...\n",
      " [ 0.05959898 -0.06248511 -0.01243587 ... -0.05505529  0.10256878\n",
      "  -0.1342663 ]\n",
      " [ 0.02986807 -0.07544731 -0.09657618 ...  0.04134127  0.04379578\n",
      "  -0.018751  ]\n",
      " [-0.13206592  0.07676896  0.09197329 ...  0.02362734 -0.1323594\n",
      "   0.09826794]]\n",
      "\n",
      "• Biases:\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "This layer has a total of 100,352 weights and 128 biases\n"
     ]
    }
   ],
   "source": [
    "w1 = my_model_2.hidden_layer_1.get_weights()[0] # getting weight numpy array\n",
    "b1 = my_model_2.hidden_layer_1.get_weights()[1] # getting bias numpy array\n",
    "\n",
    "print('\\n\\u2022 Weights:\\n', w)\n",
    "print('\\n\\u2022 Biases:\\n', b)\n",
    "print('\\nThis layer has a total of {:,} weights and {:,} biases'.format(w1.size, b1.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-y_bv6uBXvs"
   },
   "source": [
    "All the other methods we saw before, such as `.layers`, are also available for subclassed models, so feel free to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAIMbWqEpJuV"
   },
   "source": [
    "## Making Predictions with Subclassed Models\n",
    "\n",
    "Predictions are made in exactly the same way as before. So let's pass an image to our subclassed model and see what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "qFV-XUP9pKSn",
    "outputId": "957e6c81-4165-44b9-d0d4-08c3ca1b4742"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 235,
       "width": 424
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image_batch, label_batch in training_batches.take(1):\n",
    "    ps = subclassed_model.predict(image_batch)\n",
    "    first_image = image_batch.numpy().squeeze()[0]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "ax1.imshow(first_image, cmap = plt.cm.binary)\n",
    "ax1.axis('off')\n",
    "ax2.barh(np.arange(10), ps[0])\n",
    "ax2.set_aspect(0.1)\n",
    "ax2.set_yticks(np.arange(10))\n",
    "ax2.set_yticklabels(np.arange(10))\n",
    "ax2.set_title('Class Probability')\n",
    "ax2.set_xlim(0, 1.1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GI-f9IzJpO3A"
   },
   "source": [
    "As before, we can see above, our model gives every digit roughly the same probability. This means our network has basically no idea what the digit in the image is. This is because we haven't trained our model yet, so all the weights are random!\n",
    "\n",
    "In the next notebook, we'll see how we can train a neural network to accurately predict the numbers appearing in the MNIST images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vUfsknUC3ctf"
   },
   "source": [
    "## Other Methods to Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "Qlk-03oapl6S",
    "outputId": "ac7ea2e6-db22-411c-b239-446c624e7ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# we create a sequential model without any layers\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# we can add layers by using add method.\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape = (28,28,1)))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "          \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "oBmAM5Ip15Gg",
    "outputId": "ca254c0a-d6bf-45cf-a36c-3365af23d351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 56)                7224      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 28)                1596      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 14)                406       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                150       \n",
      "=================================================================\n",
      "Total params: 575,520\n",
      "Trainable params: 575,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# list number of neurons in each six hidden layer.\n",
    "layer_neurons = [512, 256, 128, 56, 28, 14]\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape = (28,28,1)))\n",
    "\n",
    "for neurons in layer_neurons:\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "            \n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "          \n",
    "model.summary()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Weo3uwdrA8di"
   },
   "source": [
    "## Clearing the Graph\n",
    "\n",
    "In order to avoid clutter from old models in the graph, we can use:\n",
    "\n",
    "```python\n",
    "tf.keras.backend.clear_session()\n",
    "```\n",
    "\n",
    "This command deletes the current `tf.keras` graph and creates a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "kZ2e667J4Bod",
    "outputId": "6d7882d3-e540-4f5e-8745-e1782c4c4dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 56)                7224      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 28)                1596      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 14)                406       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                150       \n",
      "=================================================================\n",
      "Total params: 575,520\n",
      "Trainable params: 575,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "layer_neurons = [512, 256, 128, 56, 28, 14]\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape = (28,28,1)))\n",
    "\n",
    "for neurons in layer_neurons:\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "            \n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "          \n",
    "model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZxZZdnIuA4J2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Part 2 - Neural networks with TensorFlow and Keras (Solution).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
